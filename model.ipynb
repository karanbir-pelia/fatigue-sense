{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fce7410-8811-4034-990d-db595f0c890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6bf1e7-a567-4edb-b998-298ddda2e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FatigueModelTrainer:\n",
    "    def __init__(self, data_dir, img_size=(224, 224), batch_size=32):\n",
    "        # Initialize logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        # Configuration\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        # Enable Metal backend for M1 Mac\n",
    "        try:\n",
    "            tf.config.experimental.set_visible_devices(\n",
    "                tf.config.list_physical_devices('GPU')[0], 'GPU'\n",
    "            )\n",
    "        except:\n",
    "            self.logger.warning(\"No GPU found, using CPU instead\")\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"Create the CNN model architecture using functional API\"\"\"\n",
    "        # Input layer\n",
    "        inputs = Input(shape=(*self.img_size, 3))\n",
    "\n",
    "        # First Convolutional Block\n",
    "        x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "        x = MaxPooling2D(2, 2)(x)\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "        x = MaxPooling2D(2, 2)(x)\n",
    "\n",
    "        # Third Convolutional Block\n",
    "        x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "        x = MaxPooling2D(2, 2)(x)\n",
    "\n",
    "        # Fourth Convolutional Block\n",
    "        x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "        x = MaxPooling2D(2, 2)(x)\n",
    "\n",
    "        # Flatten and Dense Layers\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        # Create model\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def setup_data_generators(self):\n",
    "        \"\"\"Set up data generators for training and validation\"\"\"\n",
    "        # Data augmentation for training\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            validation_split=0.2  # 20% for validation\n",
    "        )\n",
    "\n",
    "        # Create generators\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            self.data_dir,\n",
    "            target_size=self.img_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary',\n",
    "            subset='training'\n",
    "        )\n",
    "\n",
    "        validation_generator = train_datagen.flow_from_directory(\n",
    "            self.data_dir,\n",
    "            target_size=self.img_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary',\n",
    "            subset='validation'\n",
    "        )\n",
    "\n",
    "        return train_generator, validation_generator\n",
    "\n",
    "    def train_model(self, epochs=50):\n",
    "        \"\"\"Train the fatigue detection model\"\"\"\n",
    "        # Create model\n",
    "        model = self.create_model()\n",
    "        self.logger.info(\"Model created successfully\")\n",
    "\n",
    "        # Setup data generators\n",
    "        train_generator, validation_generator = self.setup_data_generators()\n",
    "        self.logger.info(\"Data generators created successfully\")\n",
    "\n",
    "        # Create models directory if it doesn't exist\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "\n",
    "        # Callbacks\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            'models/best_fatigue_model.keras',  # Updated extension to .keras\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            callbacks=[checkpoint, early_stopping]\n",
    "        )\n",
    "\n",
    "        # Save final model\n",
    "        model.save('models/final_fatigue_model.keras')  # Updated extension to .keras\n",
    "        self.logger.info(\"Model training completed and saved\")\n",
    "\n",
    "        return history, model\n",
    "\n",
    "    def plot_training_history(self, history):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        # Plot accuracy\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'])\n",
    "\n",
    "        # Plot loss\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'])\n",
    "\n",
    "        # Create plots directory if it doesn't exist\n",
    "        os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('plots/training_history.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c82bd9d-5902-46c7-a637-b1cb5958640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:No GPU found, using CPU instead\n",
      "INFO:__main__:Model created successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7296 images belonging to 2 classes.\n",
      "Found 1824 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Data generators created successfully\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866ms/step - accuracy: 0.6347 - loss: 0.6556\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70450, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 994ms/step - accuracy: 0.6349 - loss: 0.6554 - val_accuracy: 0.7045 - val_loss: 0.5611\n",
      "Epoch 2/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - accuracy: 0.7376 - loss: 0.5057\n",
      "Epoch 2: val_accuracy improved from 0.70450 to 0.70614, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 969ms/step - accuracy: 0.7376 - loss: 0.5057 - val_accuracy: 0.7061 - val_loss: 0.5627\n",
      "Epoch 3/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882ms/step - accuracy: 0.7578 - loss: 0.4565\n",
      "Epoch 3: val_accuracy did not improve from 0.70614\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - accuracy: 0.7578 - loss: 0.4565 - val_accuracy: 0.7045 - val_loss: 0.5835\n",
      "Epoch 4/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888ms/step - accuracy: 0.7713 - loss: 0.4360\n",
      "Epoch 4: val_accuracy improved from 0.70614 to 0.72478, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 1s/step - accuracy: 0.7713 - loss: 0.4360 - val_accuracy: 0.7248 - val_loss: 0.5364\n",
      "Epoch 5/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900ms/step - accuracy: 0.7856 - loss: 0.4239\n",
      "Epoch 5: val_accuracy improved from 0.72478 to 0.73081, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 1s/step - accuracy: 0.7856 - loss: 0.4239 - val_accuracy: 0.7308 - val_loss: 0.5087\n",
      "Epoch 6/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883ms/step - accuracy: 0.7591 - loss: 0.4378\n",
      "Epoch 6: val_accuracy did not improve from 0.73081\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 1s/step - accuracy: 0.7592 - loss: 0.4377 - val_accuracy: 0.7094 - val_loss: 0.5087\n",
      "Epoch 7/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871ms/step - accuracy: 0.7832 - loss: 0.4209\n",
      "Epoch 7: val_accuracy did not improve from 0.73081\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 997ms/step - accuracy: 0.7833 - loss: 0.4208 - val_accuracy: 0.7018 - val_loss: 0.5467\n",
      "Epoch 8/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866ms/step - accuracy: 0.7800 - loss: 0.4203\n",
      "Epoch 8: val_accuracy improved from 0.73081 to 0.73246, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 994ms/step - accuracy: 0.7801 - loss: 0.4203 - val_accuracy: 0.7325 - val_loss: 0.5271\n",
      "Epoch 9/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869ms/step - accuracy: 0.7967 - loss: 0.4060\n",
      "Epoch 9: val_accuracy improved from 0.73246 to 0.75000, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 996ms/step - accuracy: 0.7967 - loss: 0.4060 - val_accuracy: 0.7500 - val_loss: 0.4991\n",
      "Epoch 10/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868ms/step - accuracy: 0.7908 - loss: 0.4024\n",
      "Epoch 10: val_accuracy improved from 0.75000 to 0.75219, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 995ms/step - accuracy: 0.7908 - loss: 0.4024 - val_accuracy: 0.7522 - val_loss: 0.4872\n",
      "Epoch 11/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856ms/step - accuracy: 0.7983 - loss: 0.3977\n",
      "Epoch 11: val_accuracy improved from 0.75219 to 0.75439, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 983ms/step - accuracy: 0.7983 - loss: 0.3977 - val_accuracy: 0.7544 - val_loss: 0.5156\n",
      "Epoch 12/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859ms/step - accuracy: 0.7954 - loss: 0.4046\n",
      "Epoch 12: val_accuracy did not improve from 0.75439\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 988ms/step - accuracy: 0.7955 - loss: 0.4046 - val_accuracy: 0.7368 - val_loss: 0.5055\n",
      "Epoch 13/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869ms/step - accuracy: 0.8141 - loss: 0.3770\n",
      "Epoch 13: val_accuracy did not improve from 0.75439\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 997ms/step - accuracy: 0.8140 - loss: 0.3771 - val_accuracy: 0.7155 - val_loss: 0.4920\n",
      "Epoch 14/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858ms/step - accuracy: 0.8099 - loss: 0.3813\n",
      "Epoch 14: val_accuracy did not improve from 0.75439\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 984ms/step - accuracy: 0.8099 - loss: 0.3813 - val_accuracy: 0.7253 - val_loss: 0.4865\n",
      "Epoch 15/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855ms/step - accuracy: 0.8047 - loss: 0.3959\n",
      "Epoch 15: val_accuracy improved from 0.75439 to 0.77467, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 983ms/step - accuracy: 0.8047 - loss: 0.3959 - val_accuracy: 0.7747 - val_loss: 0.5073\n",
      "Epoch 16/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - accuracy: 0.8154 - loss: 0.3734\n",
      "Epoch 16: val_accuracy did not improve from 0.77467\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 971ms/step - accuracy: 0.8154 - loss: 0.3734 - val_accuracy: 0.7423 - val_loss: 0.4944\n",
      "Epoch 17/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830ms/step - accuracy: 0.8168 - loss: 0.3736\n",
      "Epoch 17: val_accuracy did not improve from 0.77467\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 959ms/step - accuracy: 0.8168 - loss: 0.3736 - val_accuracy: 0.7566 - val_loss: 0.4879\n",
      "Epoch 18/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step - accuracy: 0.8250 - loss: 0.3574\n",
      "Epoch 18: val_accuracy did not improve from 0.77467\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 967ms/step - accuracy: 0.8250 - loss: 0.3575 - val_accuracy: 0.7462 - val_loss: 0.4844\n",
      "Epoch 19/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.8225 - loss: 0.3688\n",
      "Epoch 19: val_accuracy did not improve from 0.77467\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 977ms/step - accuracy: 0.8225 - loss: 0.3688 - val_accuracy: 0.7462 - val_loss: 0.4583\n",
      "Epoch 20/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849ms/step - accuracy: 0.8306 - loss: 0.3458\n",
      "Epoch 20: val_accuracy did not improve from 0.77467\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 977ms/step - accuracy: 0.8305 - loss: 0.3459 - val_accuracy: 0.7582 - val_loss: 0.4932\n",
      "Epoch 21/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868ms/step - accuracy: 0.8253 - loss: 0.3660\n",
      "Epoch 21: val_accuracy did not improve from 0.77467\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 995ms/step - accuracy: 0.8253 - loss: 0.3660 - val_accuracy: 0.7484 - val_loss: 0.4514\n",
      "Epoch 22/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860ms/step - accuracy: 0.8377 - loss: 0.3436\n",
      "Epoch 22: val_accuracy did not improve from 0.77467\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 987ms/step - accuracy: 0.8377 - loss: 0.3436 - val_accuracy: 0.7577 - val_loss: 0.4145\n",
      "Epoch 23/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857ms/step - accuracy: 0.8487 - loss: 0.3318\n",
      "Epoch 23: val_accuracy improved from 0.77467 to 0.77741, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 984ms/step - accuracy: 0.8487 - loss: 0.3319 - val_accuracy: 0.7774 - val_loss: 0.4338\n",
      "Epoch 24/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852ms/step - accuracy: 0.8539 - loss: 0.3285\n",
      "Epoch 24: val_accuracy improved from 0.77741 to 0.82840, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 979ms/step - accuracy: 0.8539 - loss: 0.3285 - val_accuracy: 0.8284 - val_loss: 0.3432\n",
      "Epoch 25/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.8656 - loss: 0.2956\n",
      "Epoch 25: val_accuracy improved from 0.82840 to 0.82895, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 977ms/step - accuracy: 0.8656 - loss: 0.2956 - val_accuracy: 0.8289 - val_loss: 0.3378\n",
      "Epoch 26/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step - accuracy: 0.8832 - loss: 0.2716\n",
      "Epoch 26: val_accuracy improved from 0.82895 to 0.85965, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 978ms/step - accuracy: 0.8832 - loss: 0.2717 - val_accuracy: 0.8596 - val_loss: 0.2932\n",
      "Epoch 27/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.8985 - loss: 0.2547\n",
      "Epoch 27: val_accuracy did not improve from 0.85965\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 976ms/step - accuracy: 0.8986 - loss: 0.2546 - val_accuracy: 0.8547 - val_loss: 0.2963\n",
      "Epoch 28/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858ms/step - accuracy: 0.9119 - loss: 0.2331\n",
      "Epoch 28: val_accuracy improved from 0.85965 to 0.88596, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 989ms/step - accuracy: 0.9118 - loss: 0.2331 - val_accuracy: 0.8860 - val_loss: 0.2790\n",
      "Epoch 29/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811ms/step - accuracy: 0.9122 - loss: 0.2269\n",
      "Epoch 29: val_accuracy did not improve from 0.88596\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 937ms/step - accuracy: 0.9122 - loss: 0.2269 - val_accuracy: 0.8777 - val_loss: 0.2622\n",
      "Epoch 30/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806ms/step - accuracy: 0.9204 - loss: 0.2029\n",
      "Epoch 30: val_accuracy improved from 0.88596 to 0.89145, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 933ms/step - accuracy: 0.9204 - loss: 0.2029 - val_accuracy: 0.8914 - val_loss: 0.2522\n",
      "Epoch 31/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865ms/step - accuracy: 0.9243 - loss: 0.1902\n",
      "Epoch 31: val_accuracy did not improve from 0.89145\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 994ms/step - accuracy: 0.9243 - loss: 0.1902 - val_accuracy: 0.8909 - val_loss: 0.2444\n",
      "Epoch 32/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step - accuracy: 0.9335 - loss: 0.1797\n",
      "Epoch 32: val_accuracy did not improve from 0.89145\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 961ms/step - accuracy: 0.9335 - loss: 0.1797 - val_accuracy: 0.8871 - val_loss: 0.2690\n",
      "Epoch 33/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905ms/step - accuracy: 0.9274 - loss: 0.1872\n",
      "Epoch 33: val_accuracy improved from 0.89145 to 0.90186, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 1s/step - accuracy: 0.9274 - loss: 0.1872 - val_accuracy: 0.9019 - val_loss: 0.2399\n",
      "Epoch 34/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - accuracy: 0.9336 - loss: 0.1705\n",
      "Epoch 34: val_accuracy did not improve from 0.90186\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 1s/step - accuracy: 0.9335 - loss: 0.1705 - val_accuracy: 0.8849 - val_loss: 0.2506\n",
      "Epoch 35/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913ms/step - accuracy: 0.9333 - loss: 0.1679\n",
      "Epoch 35: val_accuracy did not improve from 0.90186\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 1s/step - accuracy: 0.9332 - loss: 0.1679 - val_accuracy: 0.8865 - val_loss: 0.2415\n",
      "Epoch 36/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9270 - loss: 0.1828\n",
      "Epoch 36: val_accuracy improved from 0.90186 to 0.90461, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 1s/step - accuracy: 0.9270 - loss: 0.1828 - val_accuracy: 0.9046 - val_loss: 0.2258\n",
      "Epoch 37/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982ms/step - accuracy: 0.9400 - loss: 0.1613\n",
      "Epoch 37: val_accuracy did not improve from 0.90461\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 1s/step - accuracy: 0.9400 - loss: 0.1613 - val_accuracy: 0.8887 - val_loss: 0.2658\n",
      "Epoch 38/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - accuracy: 0.9363 - loss: 0.1618\n",
      "Epoch 38: val_accuracy did not improve from 0.90461\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 963ms/step - accuracy: 0.9363 - loss: 0.1619 - val_accuracy: 0.9046 - val_loss: 0.2307\n",
      "Epoch 39/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step - accuracy: 0.9364 - loss: 0.1684\n",
      "Epoch 39: val_accuracy did not improve from 0.90461\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 954ms/step - accuracy: 0.9364 - loss: 0.1683 - val_accuracy: 0.9002 - val_loss: 0.2343\n",
      "Epoch 40/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - accuracy: 0.9370 - loss: 0.1538\n",
      "Epoch 40: val_accuracy did not improve from 0.90461\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 942ms/step - accuracy: 0.9369 - loss: 0.1538 - val_accuracy: 0.8936 - val_loss: 0.2438\n",
      "Epoch 41/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814ms/step - accuracy: 0.9401 - loss: 0.1556\n",
      "Epoch 41: val_accuracy did not improve from 0.90461\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 941ms/step - accuracy: 0.9401 - loss: 0.1556 - val_accuracy: 0.8947 - val_loss: 0.2289\n",
      "Epoch 42/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - accuracy: 0.9406 - loss: 0.1547\n",
      "Epoch 42: val_accuracy did not improve from 0.90461\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 946ms/step - accuracy: 0.9406 - loss: 0.1546 - val_accuracy: 0.8975 - val_loss: 0.2249\n",
      "Epoch 43/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step - accuracy: 0.9439 - loss: 0.1504\n",
      "Epoch 43: val_accuracy did not improve from 0.90461\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 946ms/step - accuracy: 0.9438 - loss: 0.1504 - val_accuracy: 0.9019 - val_loss: 0.2316\n",
      "Epoch 44/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - accuracy: 0.9429 - loss: 0.1528\n",
      "Epoch 44: val_accuracy improved from 0.90461 to 0.90844, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 948ms/step - accuracy: 0.9429 - loss: 0.1528 - val_accuracy: 0.9084 - val_loss: 0.2054\n",
      "Epoch 45/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820ms/step - accuracy: 0.9388 - loss: 0.1581\n",
      "Epoch 45: val_accuracy improved from 0.90844 to 0.91173, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 947ms/step - accuracy: 0.9388 - loss: 0.1581 - val_accuracy: 0.9117 - val_loss: 0.1997\n",
      "Epoch 46/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823ms/step - accuracy: 0.9416 - loss: 0.1467\n",
      "Epoch 46: val_accuracy improved from 0.91173 to 0.91557, saving model to models/best_fatigue_model.keras\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 949ms/step - accuracy: 0.9416 - loss: 0.1467 - val_accuracy: 0.9156 - val_loss: 0.1913\n",
      "Epoch 47/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - accuracy: 0.9429 - loss: 0.1473\n",
      "Epoch 47: val_accuracy did not improve from 0.91557\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 974ms/step - accuracy: 0.9429 - loss: 0.1473 - val_accuracy: 0.9139 - val_loss: 0.2230\n",
      "Epoch 48/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - accuracy: 0.9467 - loss: 0.1386\n",
      "Epoch 48: val_accuracy did not improve from 0.91557\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 955ms/step - accuracy: 0.9467 - loss: 0.1387 - val_accuracy: 0.8975 - val_loss: 0.2441\n",
      "Epoch 49/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824ms/step - accuracy: 0.9470 - loss: 0.1453\n",
      "Epoch 49: val_accuracy did not improve from 0.91557\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 950ms/step - accuracy: 0.9470 - loss: 0.1453 - val_accuracy: 0.9046 - val_loss: 0.2257\n",
      "Epoch 50/50\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 0.9412 - loss: 0.1403\n",
      "Epoch 50: val_accuracy did not improve from 0.91557\n",
      "\u001b[1m228/228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 952ms/step - accuracy: 0.9412 - loss: 0.1404 - val_accuracy: 0.9035 - val_loss: 0.2238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model training completed and saved\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = FatigueModelTrainer(\n",
    "        data_dir='dataset',  # Make sure the 'dataset' folder is in the current directory\n",
    "        img_size=(224, 224),\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    history, model = trainer.train_model(epochs=50)\n",
    "\n",
    "    # Plot training history\n",
    "    trainer.plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345cd32c-869f-4a16-b750-c7112b2c2491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
